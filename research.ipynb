{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,precision_recall_fscore_support\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=pd.read_excel(\"case_study1.xlsx\")\n",
    "a2=pd.read_excel(\"case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=a1.copy()\n",
    "df2=a2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EDA\n",
    "#removing null\n",
    "df1=df1.loc[df1['Age_Oldest_TL']!=-99999]\n",
    "\n",
    "colums_to_be_removed=[]\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i]==-99999].shape[0]>10000:\n",
    "        colums_to_be_removed.append(i)\n",
    "\n",
    "df2=df2.drop(colums_to_be_removed,axis=1)\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2=df2.loc[df2[i]!=-99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging data\n",
    "\n",
    "df=pd.merge(df1, df2,how='inner',left_on=['PROSPECTID'],right_on=['PROSPECTID'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# Check categorical columns\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Test of Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective:\n",
    "The Chi-square test of independence evaluates whether there is a significant relationship between two categorical variables. In this case, you are testing the relationship between each categorical feature (MARITALSTATUS, EDUCATION, GENDER, last_prod_enq2, first_prod_enq2) and the target variable (Approved_Flag).\n",
    "\n",
    "### Hypotheses:\n",
    "\n",
    "* Null Hypothesis (𝐻_0): The two variables are independent (no association).\n",
    "* Alternative Hypothesis (𝐻_𝑎): The two variables are not independent (there is an association).\n",
    "Interpretation:\n",
    "\n",
    "A low p-value (typically ≤ 0.05) indicates that you can reject the null hypothesis, suggesting a significant association between the variables.\n",
    "A high p-value (> 0.05) indicates that you cannot reject the null hypothesis, suggesting no significant association between the variables.\n",
    "\n",
    "### Results Interpretation\n",
    "Here are the p-values you provided:\n",
    "\n",
    "MARITALSTATUS: \n",
    "3.578\n",
    "×\n",
    "1\n",
    "0\n",
    "−\n",
    "233\n",
    "3.578×10 \n",
    "−233\n",
    " \n",
    "EDUCATION: \n",
    "2.694\n",
    "×\n",
    "1\n",
    "0\n",
    "−\n",
    "30\n",
    "2.694×10 \n",
    "−30\n",
    " \n",
    "GENDER: \n",
    "1.908\n",
    "×\n",
    "1\n",
    "0\n",
    "−\n",
    "5\n",
    "1.908×10 \n",
    "−5\n",
    " \n",
    "last_prod_enq2: \n",
    "0.0\n",
    "0.0\n",
    "first_prod_enq2: \n",
    "7.850\n",
    "×\n",
    "1\n",
    "0\n",
    "−\n",
    "287\n",
    "7.850×10 \n",
    "−287\n",
    " \n",
    "### Interpretation:\n",
    "\n",
    "MARITALSTATUS: The p-value is extremely low, indicating a significant association between marital status and the approval flag.\n",
    "\n",
    "EDUCATION: The p-value is very low, indicating a significant association between education and the approval flag.\n",
    "\n",
    "GENDER: The p-value is low, indicating a significant association between gender and the approval flag.\n",
    "\n",
    "last_prod_enq2: The p-value is effectively zero, indicating a very strong association between the last product enquiry type and the approval flag.\n",
    "\n",
    "first_prod_enq2: The p-value is extremely low, indicating a significant association between the first product enquiry type and the approval flag.\n",
    "\n",
    "In summary, all the tested categorical features (MARITALSTATUS, EDUCATION, GENDER, last_prod_enq2, first_prod_enq2) have a significant association with the approval flag (Approved_Flag). This means that these features can be considered important in predicting the target variable and should be included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.5781808610388605e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.9079361001865664e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.849976105554191e-287\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test for categorical features\n",
    "from scipy.stats import chi2_contingency\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant numerical columns\n",
    "numeric_columns = [col for col in df.columns if df[col].dtype != 'object' and col not in ['PROSPECTID', 'Approved_Flag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Variance Inflation Factor (VIF) measures the amount of multicollinearity (correlation between predictor variables) in a regression model. High multicollinearity can inflate the variance of coefficient estimates and make the model unstable.\n",
    "\n",
    "### Interpretation:\n",
    "VIF = 1: No correlation between the predictor and other variables.\n",
    "\n",
    "1 < VIF < 5: Moderate correlation but not severe.\n",
    "\n",
    "VIF > 5: High correlation that may be problematic.\n",
    "\n",
    "VIF > 10: Very high correlation, indicating severe multicollinearity, and the variable should likely be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factor (VIF) to remove multicollinear features\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load the numeric columns data\n",
    "vif_data = df[numeric_columns].copy()\n",
    "columns_to_be_kept = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Total_TL with VIF inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Tot_Closed_TL with VIF inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping pct_active_tl with VIF inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Auto_TL with VIF inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping num_deliq_6mts with VIF inf\n",
      "Dropping pct_of_active_TLs_ever with VIF 2688.950269071678\n",
      "Dropping Secured_TL with VIF 91.06825895268156\n",
      "Dropping enq_L12m with VIF 36.973403461591815\n",
      "Dropping Credit_Score with VIF 33.37615091051607\n",
      "Dropping num_std_12mts with VIF 26.132728283549536\n",
      "Dropping pct_PL_enq_L6m_of_L12m with VIF 24.111711369003796\n",
      "Dropping Total_TL_opened_L12M with VIF 22.140448203659652\n",
      "Dropping Unsecured_TL with VIF 19.94482644532673\n",
      "Dropping pct_CC_enq_L6m_of_L12m with VIF 19.1598991176436\n",
      "Dropping enq_L6m with VIF 16.71623271795243\n",
      "Dropping num_times_30p_dpd with VIF 13.67574175637928\n",
      "Dropping AGE with VIF 12.91749147385467\n",
      "Dropping PL_enq_L12m with VIF 12.431183953953077\n",
      "Dropping Tot_Active_TL with VIF 12.316359114662921\n",
      "Columns to be kept based on VIF: ['Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M', 'pct_tl_closed_L6M', 'pct_closed_tl', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Other_TL', 'Age_Oldest_TL', 'Age_Newest_TL', 'time_since_recent_payment', 'num_times_delinquent', 'max_recent_level_of_deliq', 'num_deliq_12mts', 'num_deliq_6_12mts', 'num_times_60p_dpd', 'num_std', 'num_std_6mts', 'num_sub', 'num_sub_6mts', 'num_sub_12mts', 'num_dbt', 'num_dbt_6mts', 'num_dbt_12mts', 'num_lss', 'num_lss_6mts', 'num_lss_12mts', 'recent_level_of_deliq', 'tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'time_since_recent_enq', 'enq_L3m', 'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL', 'CC_Flag', 'PL_Flag', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_ever', 'HL_Flag', 'GL_Flag']\n"
     ]
    }
   ],
   "source": [
    "# Calculate VIF for each feature and remove those with high multicollinearity\n",
    "while True:\n",
    "    vif_values = [variance_inflation_factor(vif_data.values, i) for i in range(vif_data.shape[1])]\n",
    "    max_vif = max(vif_values)\n",
    "    max_vif_index = vif_values.index(max_vif)\n",
    "    \n",
    "    if max_vif > 10:\n",
    "        print(f\"Dropping {vif_data.columns[max_vif_index]} with VIF {max_vif}\")\n",
    "        vif_data.drop(vif_data.columns[max_vif_index], axis=1, inplace=True)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Update the columns to be kept based on VIF\n",
    "columns_to_be_kept = vif_data.columns.tolist()\n",
    "print(\"Columns to be kept based on VIF:\", columns_to_be_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_to_be_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Analysis of Variance (ANOVA) test is used to determine if there are statistically significant differences between the means of three or more independent (unrelated) groups. In the context of your code, it's used to determine whether each numerical feature significantly differs across the categories of the target variable Approved_Flag.\n",
    "\n",
    "### Hypotheses:\n",
    "Null Hypothesis (𝐻_0): The means of the different groups are equal (i.e., there is no significant difference between groups).\n",
    "\n",
    "Alternative Hypothesis (𝐻_𝑎): At least one group mean is different from the others (i.e., there is a significant difference between groups).\n",
    "\n",
    "### Steps in the ANOVA Test:\n",
    "Partitioning the Data: The numerical feature data is partitioned into groups based on the levels of the categorical variable (here, Approved_Flag).\n",
    "\n",
    "Calculate F-statistic: The F-statistic is calculated by comparing the variance between the groups to the variance within the groups.\n",
    "\n",
    "Compute p-value: The p-value indicates the probability that the observed differences are due to chance.\n",
    "Interpretation of p-value:\n",
    "\n",
    "* p-value ≤ 0.05: Reject the null hypothesis. There is a statistically significant difference between the means of the groups.\n",
    "* p-value > 0.05: Fail to reject the null hypothesis. There is no statistically significant difference between the means of the groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA test for numerical features\n",
    "columns_to_be_kept_numerical = []\n",
    "for i in columns_to_be_kept:\n",
    "    groups = [list(df[df['Approved_Flag'] == group][i]) for group in df['Approved_Flag'].unique()]\n",
    "    f_statistic, p_value = f_oneway(*groups)\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_to_be_kept_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 56 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Total_TL_opened_L6M         42064 non-null  int64  \n",
      " 1   Tot_TL_closed_L6M           42064 non-null  int64  \n",
      " 2   pct_tl_open_L6M             42064 non-null  float64\n",
      " 3   pct_tl_closed_L6M           42064 non-null  float64\n",
      " 4   pct_closed_tl               42064 non-null  float64\n",
      " 5   Tot_TL_closed_L12M          42064 non-null  int64  \n",
      " 6   pct_tl_open_L12M            42064 non-null  float64\n",
      " 7   pct_tl_closed_L12M          42064 non-null  float64\n",
      " 8   Tot_Missed_Pmnt             42064 non-null  int64  \n",
      " 9   CC_TL                       42064 non-null  int64  \n",
      " 10  Consumer_TL                 42064 non-null  int64  \n",
      " 11  Gold_TL                     42064 non-null  int64  \n",
      " 12  Home_TL                     42064 non-null  int64  \n",
      " 13  PL_TL                       42064 non-null  int64  \n",
      " 14  Other_TL                    42064 non-null  int64  \n",
      " 15  Age_Oldest_TL               42064 non-null  int64  \n",
      " 16  Age_Newest_TL               42064 non-null  int64  \n",
      " 17  time_since_recent_payment   42064 non-null  int64  \n",
      " 18  num_times_delinquent        42064 non-null  int64  \n",
      " 19  max_recent_level_of_deliq   42064 non-null  int64  \n",
      " 20  num_deliq_12mts             42064 non-null  int64  \n",
      " 21  num_deliq_6_12mts           42064 non-null  int64  \n",
      " 22  num_times_60p_dpd           42064 non-null  int64  \n",
      " 23  num_std                     42064 non-null  int64  \n",
      " 24  num_std_6mts                42064 non-null  int64  \n",
      " 25  num_sub                     42064 non-null  int64  \n",
      " 26  num_sub_6mts                42064 non-null  int64  \n",
      " 27  num_sub_12mts               42064 non-null  int64  \n",
      " 28  num_dbt                     42064 non-null  int64  \n",
      " 29  num_dbt_6mts                42064 non-null  int64  \n",
      " 30  num_dbt_12mts               42064 non-null  int64  \n",
      " 31  num_lss                     42064 non-null  int64  \n",
      " 32  recent_level_of_deliq       42064 non-null  int64  \n",
      " 33  tot_enq                     42064 non-null  int64  \n",
      " 34  CC_enq                      42064 non-null  int64  \n",
      " 35  CC_enq_L6m                  42064 non-null  int64  \n",
      " 36  CC_enq_L12m                 42064 non-null  int64  \n",
      " 37  PL_enq                      42064 non-null  int64  \n",
      " 38  PL_enq_L6m                  42064 non-null  int64  \n",
      " 39  time_since_recent_enq       42064 non-null  int64  \n",
      " 40  enq_L3m                     42064 non-null  int64  \n",
      " 41  NETMONTHLYINCOME            42064 non-null  int64  \n",
      " 42  Time_With_Curr_Empr         42064 non-null  int64  \n",
      " 43  pct_opened_TLs_L6m_of_L12m  42064 non-null  float64\n",
      " 44  CC_Flag                     42064 non-null  int64  \n",
      " 45  PL_Flag                     42064 non-null  int64  \n",
      " 46  pct_PL_enq_L6m_of_ever      42064 non-null  float64\n",
      " 47  pct_CC_enq_L6m_of_ever      42064 non-null  float64\n",
      " 48  HL_Flag                     42064 non-null  int64  \n",
      " 49  GL_Flag                     42064 non-null  int64  \n",
      " 50  MARITALSTATUS               42064 non-null  object \n",
      " 51  EDUCATION                   42064 non-null  int64  \n",
      " 52  GENDER                      42064 non-null  object \n",
      " 53  last_prod_enq2              42064 non-null  object \n",
      " 54  first_prod_enq2             42064 non-null  object \n",
      " 55  Approved_Flag               42064 non-null  object \n",
      "dtypes: float64(8), int64(43), object(5)\n",
      "memory usage: 18.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/41js8vcx7_v0crff6_9rfj_h0000gn/T/ipykernel_1988/3394167619.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['EDUCATION'] = df['EDUCATION'].replace({\n"
     ]
    }
   ],
   "source": [
    "# Label encoding for categorical features\n",
    "df['EDUCATION'] = df['EDUCATION'].replace({\n",
    "    'SSC': 1,\n",
    "    '12TH': 2,\n",
    "    'GRADUATE': 3,\n",
    "    'UNDER GRADUATE': 3,\n",
    "    'OTHERS': 1,\n",
    "    'POST-GRADUATE': 4,\n",
    "    'PROFESSIONAL': 3\n",
    "})\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=[\"MARITALSTATUS\", 'GENDER', 'last_prod_enq2', 'first_prod_enq2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection using RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_names = x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by importance\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Age_Oldest_TL</td>\n",
       "      <td>0.126006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>enq_L3m</td>\n",
       "      <td>0.086309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>time_since_recent_enq</td>\n",
       "      <td>0.079656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>num_std</td>\n",
       "      <td>0.047524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_since_recent_payment</td>\n",
       "      <td>0.042522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>num_sub_12mts</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>num_lss</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>num_sub_6mts</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>num_dbt_12mts</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>num_dbt_6mts</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Importance\n",
       "15              Age_Oldest_TL    0.126006\n",
       "40                    enq_L3m    0.086309\n",
       "39      time_since_recent_enq    0.079656\n",
       "23                    num_std    0.047524\n",
       "17  time_since_recent_payment    0.042522\n",
       "..                        ...         ...\n",
       "27              num_sub_12mts    0.000346\n",
       "31                    num_lss    0.000194\n",
       "26               num_sub_6mts    0.000148\n",
       "30              num_dbt_12mts    0.000092\n",
       "29               num_dbt_6mts    0.000032\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features based on importance:\n",
      "                         Feature  Importance\n",
      "15                 Age_Oldest_TL    0.126006\n",
      "40                       enq_L3m    0.086309\n",
      "39         time_since_recent_enq    0.079656\n",
      "23                       num_std    0.047524\n",
      "17     time_since_recent_payment    0.042522\n",
      "42           Time_With_Curr_Empr    0.038820\n",
      "41              NETMONTHLYINCOME    0.034316\n",
      "16                 Age_Newest_TL    0.032184\n",
      "24                  num_std_6mts    0.031987\n",
      "33                       tot_enq    0.031887\n",
      "46        pct_PL_enq_L6m_of_ever    0.029913\n",
      "32         recent_level_of_deliq    0.025623\n",
      "6               pct_tl_open_L12M    0.024062\n",
      "19     max_recent_level_of_deliq    0.023846\n",
      "4                  pct_closed_tl    0.023192\n",
      "18          num_times_delinquent    0.019986\n",
      "38                    PL_enq_L6m    0.019593\n",
      "14                      Other_TL    0.016838\n",
      "2                pct_tl_open_L6M    0.014646\n",
      "10                   Consumer_TL    0.014484\n",
      "37                        PL_enq    0.014465\n",
      "50                     EDUCATION    0.014128\n",
      "7             pct_tl_closed_L12M    0.013670\n",
      "11                       Gold_TL    0.011113\n",
      "20               num_deliq_12mts    0.010278\n",
      "3              pct_tl_closed_L6M    0.010105\n",
      "8                Tot_Missed_Pmnt    0.009394\n",
      "43    pct_opened_TLs_L6m_of_L12m    0.009132\n",
      "5             Tot_TL_closed_L12M    0.008611\n",
      "0            Total_TL_opened_L6M    0.008345\n",
      "57   last_prod_enq2_ConsumerLoan    0.006928\n",
      "66        first_prod_enq2_others    0.006595\n",
      "22             num_times_60p_dpd    0.006421\n",
      "13                         PL_TL    0.006334\n",
      "1              Tot_TL_closed_L6M    0.006192\n",
      "34                        CC_enq    0.006072\n",
      "63  first_prod_enq2_ConsumerLoan    0.005853\n",
      "51         MARITALSTATUS_Married    0.005713\n",
      "21             num_deliq_6_12mts    0.005701\n",
      "52          MARITALSTATUS_Single    0.005585\n",
      "60         last_prod_enq2_others    0.005327\n",
      "36                   CC_enq_L12m    0.004785\n",
      "48                       HL_Flag    0.004610\n",
      "47        pct_CC_enq_L6m_of_ever    0.004110\n",
      "35                    CC_enq_L6m    0.004079\n",
      "53                      GENDER_F    0.004036\n",
      "54                      GENDER_M    0.003983\n",
      "45                       PL_Flag    0.003826\n",
      "59             last_prod_enq2_PL    0.003703\n",
      "9                          CC_TL    0.003671\n"
     ]
    }
   ],
   "source": [
    "# Display the top features\n",
    "print(\"Top features based on importance:\")\n",
    "print(feature_importances.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features based on cumulative importance up to 95.0%:\n",
      "15                   Age_Oldest_TL\n",
      "40                         enq_L3m\n",
      "39           time_since_recent_enq\n",
      "23                         num_std\n",
      "17       time_since_recent_payment\n",
      "42             Time_With_Curr_Empr\n",
      "41                NETMONTHLYINCOME\n",
      "16                   Age_Newest_TL\n",
      "24                    num_std_6mts\n",
      "33                         tot_enq\n",
      "46          pct_PL_enq_L6m_of_ever\n",
      "32           recent_level_of_deliq\n",
      "6                 pct_tl_open_L12M\n",
      "19       max_recent_level_of_deliq\n",
      "4                    pct_closed_tl\n",
      "18            num_times_delinquent\n",
      "38                      PL_enq_L6m\n",
      "14                        Other_TL\n",
      "2                  pct_tl_open_L6M\n",
      "10                     Consumer_TL\n",
      "37                          PL_enq\n",
      "50                       EDUCATION\n",
      "7               pct_tl_closed_L12M\n",
      "11                         Gold_TL\n",
      "20                 num_deliq_12mts\n",
      "3                pct_tl_closed_L6M\n",
      "8                  Tot_Missed_Pmnt\n",
      "43      pct_opened_TLs_L6m_of_L12m\n",
      "5               Tot_TL_closed_L12M\n",
      "0              Total_TL_opened_L6M\n",
      "57     last_prod_enq2_ConsumerLoan\n",
      "66          first_prod_enq2_others\n",
      "22               num_times_60p_dpd\n",
      "13                           PL_TL\n",
      "1                Tot_TL_closed_L6M\n",
      "34                          CC_enq\n",
      "63    first_prod_enq2_ConsumerLoan\n",
      "51           MARITALSTATUS_Married\n",
      "21               num_deliq_6_12mts\n",
      "52            MARITALSTATUS_Single\n",
      "60           last_prod_enq2_others\n",
      "36                     CC_enq_L12m\n",
      "48                         HL_Flag\n",
      "Name: Feature, dtype: object\n",
      "Number of selected features: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming feature_importances is a DataFrame with Feature and Importance columns\n",
    "# Calculate cumulative importance\n",
    "feature_importances['Cumulative Importance'] = feature_importances['Importance'].cumsum()\n",
    "\n",
    "# Set the threshold for cumulative importance\n",
    "threshold = 0.95\n",
    "\n",
    "# Select features contributing to the cumulative importance below the threshold\n",
    "selected_features = feature_importances[feature_importances['Cumulative Importance'] <= threshold]['Feature']\n",
    "\n",
    "print(f\"Selected features based on cumulative importance up to {threshold * 100}%:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Print number of selected features\n",
    "print(f\"Number of selected features: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting number of features by testing on RF and XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(x_train, x_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    rf_classifier.fit(x_train, y_train)\n",
    "    y_pred_rf = rf_classifier.predict(x_test)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "    results['Random Forest'] = {\n",
    "        'Accuracy': accuracy_rf,\n",
    "        'Precision': precision_rf,\n",
    "        'Recall': recall_rf,\n",
    "        'F1 Score': f1_score_rf\n",
    "    }\n",
    "\n",
    "    # XGBoost Classifier\n",
    "    xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "    xgb_classifier.fit(x_train, y_train)\n",
    "    y_pred_xgb = xgb_classifier.predict(x_test)\n",
    "    accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "    precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "    results['XGBoost'] = {\n",
    "        'Accuracy': accuracy_xgb,\n",
    "        'Precision': precision_xgb,\n",
    "        'Recall': recall_xgb,\n",
    "        'F1 Score': f1_score_xgb\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select top N features and evaluate classifiers\n",
    "def evaluate_with_top_features(df_encoded, feature_importances, num_features):\n",
    "    # Select top N features based on importance\n",
    "    selected_features = feature_importances.head(num_features)['Feature']\n",
    "    \n",
    "    # Prepare data\n",
    "    y = df_encoded['Approved_Flag']\n",
    "    x = df_encoded[selected_features]\n",
    "\n",
    "    # Encode target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Split the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train and evaluate classifiers\n",
    "    results = train_and_evaluate(x_train, x_test, y_train, y_test)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers with different numbers of top features\n",
    "num_features_list = [10, 20, 30, 40, 50]\n",
    "evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_features in num_features_list:\n",
    "    results = evaluate_with_top_features(df_encoded, feature_importances, num_features)\n",
    "    evaluation_results[num_features] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with top 10 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7285\n",
      "  Precision: 0.6949\n",
      "  Recall: 0.7285\n",
      "  F1 Score: 0.7003\n",
      "XGBoost:\n",
      "  Accuracy: 0.7302\n",
      "  Precision: 0.6994\n",
      "  Recall: 0.7302\n",
      "  F1 Score: 0.7032\n",
      "\n",
      "Results with top 20 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7706\n",
      "  Precision: 0.7457\n",
      "  Recall: 0.7706\n",
      "  F1 Score: 0.7515\n",
      "XGBoost:\n",
      "  Accuracy: 0.7738\n",
      "  Precision: 0.7527\n",
      "  Recall: 0.7738\n",
      "  F1 Score: 0.7590\n",
      "\n",
      "Results with top 30 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7713\n",
      "  Precision: 0.7459\n",
      "  Recall: 0.7713\n",
      "  F1 Score: 0.7510\n",
      "XGBoost:\n",
      "  Accuracy: 0.7801\n",
      "  Precision: 0.7603\n",
      "  Recall: 0.7801\n",
      "  F1 Score: 0.7663\n",
      "\n",
      "Results with top 40 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7742\n",
      "  Precision: 0.7494\n",
      "  Recall: 0.7742\n",
      "  F1 Score: 0.7527\n",
      "XGBoost:\n",
      "  Accuracy: 0.7820\n",
      "  Precision: 0.7633\n",
      "  Recall: 0.7820\n",
      "  F1 Score: 0.7690\n",
      "\n",
      "Results with top 50 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7701\n",
      "  Precision: 0.7437\n",
      "  Recall: 0.7701\n",
      "  F1 Score: 0.7482\n",
      "XGBoost:\n",
      "  Accuracy: 0.7783\n",
      "  Precision: 0.7587\n",
      "  Recall: 0.7783\n",
      "  F1 Score: 0.7645\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation results\n",
    "for num_features, results in evaluation_results.items():\n",
    "    print(f\"\\nResults with top {num_features} features:\")\n",
    "    for classifier, metrics in results.items():\n",
    "        print(f\"{classifier}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifiers with different numbers of top features\n",
    "num_features_list = [12, 15, 18]\n",
    "evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_features in num_features_list:\n",
    "    results = evaluate_with_top_features(df_encoded, feature_importances, num_features)\n",
    "    evaluation_results[num_features] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with top 12 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7685\n",
      "  Precision: 0.7443\n",
      "  Recall: 0.7685\n",
      "  F1 Score: 0.7507\n",
      "XGBoost:\n",
      "  Accuracy: 0.7730\n",
      "  Precision: 0.7519\n",
      "  Recall: 0.7730\n",
      "  F1 Score: 0.7581\n",
      "\n",
      "Results with top 15 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7675\n",
      "  Precision: 0.7430\n",
      "  Recall: 0.7675\n",
      "  F1 Score: 0.7490\n",
      "XGBoost:\n",
      "  Accuracy: 0.7723\n",
      "  Precision: 0.7512\n",
      "  Recall: 0.7723\n",
      "  F1 Score: 0.7573\n",
      "\n",
      "Results with top 18 features:\n",
      "Random Forest:\n",
      "  Accuracy: 0.7717\n",
      "  Precision: 0.7486\n",
      "  Recall: 0.7717\n",
      "  F1 Score: 0.7544\n",
      "XGBoost:\n",
      "  Accuracy: 0.7726\n",
      "  Precision: 0.7512\n",
      "  Recall: 0.7726\n",
      "  F1 Score: 0.7579\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation results\n",
    "for num_features, results in evaluation_results.items():\n",
    "    print(f\"\\nResults with top {num_features} features:\")\n",
    "    for classifier, metrics in results.items():\n",
    "        print(f\"{classifier}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Finally selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_importances.head(12)['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15                Age_Oldest_TL\n",
       "40                      enq_L3m\n",
       "39        time_since_recent_enq\n",
       "23                      num_std\n",
       "17    time_since_recent_payment\n",
       "42          Time_With_Curr_Empr\n",
       "41             NETMONTHLYINCOME\n",
       "16                Age_Newest_TL\n",
       "24                 num_std_6mts\n",
       "33                      tot_enq\n",
       "46       pct_PL_enq_L6m_of_ever\n",
       "32        recent_level_of_deliq\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <th>enq_L3m</th>\n",
       "      <th>time_since_recent_enq</th>\n",
       "      <th>num_std</th>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <th>Time_With_Curr_Empr</th>\n",
       "      <th>NETMONTHLYINCOME</th>\n",
       "      <th>Age_Newest_TL</th>\n",
       "      <th>num_std_6mts</th>\n",
       "      <th>tot_enq</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>recent_level_of_deliq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>566</td>\n",
       "      <td>21</td>\n",
       "      <td>549</td>\n",
       "      <td>114</td>\n",
       "      <td>51000</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>19000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>587</td>\n",
       "      <td>10</td>\n",
       "      <td>302</td>\n",
       "      <td>191</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>3951</td>\n",
       "      <td>53</td>\n",
       "      <td>583</td>\n",
       "      <td>75</td>\n",
       "      <td>15000</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>245</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.429</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42059</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>249</td>\n",
       "      <td>18500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42060</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>186</td>\n",
       "      <td>25000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42061</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>18000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42062</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>54</td>\n",
       "      <td>12802</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42063</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>102</td>\n",
       "      <td>16000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42064 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age_Oldest_TL  enq_L3m  time_since_recent_enq  num_std  \\\n",
       "0                 72        0                    566       21   \n",
       "1                  7        0                    209        0   \n",
       "2                 47        0                    587       10   \n",
       "3                131        0                   3951       53   \n",
       "4                150        4                      7        5   \n",
       "...              ...      ...                    ...      ...   \n",
       "42059             24        1                      0        0   \n",
       "42060             74        0                    203        6   \n",
       "42061              9        2                      1        0   \n",
       "42062             15        0                    242        0   \n",
       "42063             20        1                     13       18   \n",
       "\n",
       "       time_since_recent_payment  Time_With_Curr_Empr  NETMONTHLYINCOME  \\\n",
       "0                            549                  114             51000   \n",
       "1                             47                   50             19000   \n",
       "2                            302                  191                18   \n",
       "3                            583                   75             15000   \n",
       "4                            245                  154                 0   \n",
       "...                          ...                  ...               ...   \n",
       "42059                         15                  249             18500   \n",
       "42060                         57                  186             25000   \n",
       "42061                         32                   66             18000   \n",
       "42062                         58                   54             12802   \n",
       "42063                         74                  102             16000   \n",
       "\n",
       "       Age_Newest_TL  num_std_6mts  tot_enq  pct_PL_enq_L6m_of_ever  \\\n",
       "0                 18             5        6                   0.000   \n",
       "1                  7             0        1                   0.000   \n",
       "2                  2             5        4                   0.000   \n",
       "3                 32             4        1                   0.000   \n",
       "4                 17             0       15                   0.429   \n",
       "...              ...           ...      ...                     ...   \n",
       "42059              5             0        4                   0.000   \n",
       "42060              7             4        2                   0.000   \n",
       "42061              5             0        6                   1.000   \n",
       "42062              8             0        3                   0.000   \n",
       "42063             20             4        2                   0.000   \n",
       "\n",
       "       recent_level_of_deliq  \n",
       "0                         29  \n",
       "1                          0  \n",
       "2                         25  \n",
       "3                          0  \n",
       "4                         26  \n",
       "...                      ...  \n",
       "42059                     24  \n",
       "42060                      0  \n",
       "42061                      0  \n",
       "42062                      0  \n",
       "42063                      0  \n",
       "\n",
       "[42064 rows x 12 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        P2\n",
       "1        P2\n",
       "2        P2\n",
       "3        P1\n",
       "4        P3\n",
       "         ..\n",
       "42059    P4\n",
       "42060    P1\n",
       "42061    P3\n",
       "42062    P2\n",
       "42063    P2\n",
       "Name: Approved_Flag, Length: 42064, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/41js8vcx7_v0crff6_9rfj_h0000gn/T/ipykernel_1988/4243331543.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_encoded['Approved_Flag_Encoded'] = df_encoded['Approved_Flag'].replace({'P1': 0, 'P2': 1, 'P3': 2, 'P4': 3})\n"
     ]
    }
   ],
   "source": [
    "# Manually encode target variable\n",
    "df_encoded['Approved_Flag_Encoded'] = df_encoded['Approved_Flag'].replace({'P1': 0, 'P2': 1, 'P3': 2, 'P4': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data with the top 12 features for testing\n",
    "selected_features = feature_importances.head(12)['Feature']\n",
    "y = df_encoded['Approved_Flag_Encoded']\n",
    "x = df_encoded[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store models and their names\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(objective='multi:softmax', num_class=4, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers with a given set of features\n",
    "def train_and_evaluate_model(model, x_train, x_test, y_train, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n",
      "  Accuracy: 0.7685\n",
      "  Precision: 0.7443\n",
      "  Recall: 0.7685\n",
      "  F1 Score: 0.7507\n",
      "\n",
      "XGBoost:\n",
      "  Accuracy: 0.7730\n",
      "  Precision: 0.7519\n",
      "  Recall: 0.7730\n",
      "  F1 Score: 0.7581\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.6351\n",
      "  Precision: 0.5344\n",
      "  Recall: 0.6351\n",
      "  F1 Score: 0.5463\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "  Accuracy: 0.6164\n",
      "  Precision: 0.5737\n",
      "  Recall: 0.6164\n",
      "  F1 Score: 0.5770\n",
      "\n",
      "Decision Tree:\n",
      "  Accuracy: 0.6952\n",
      "  Precision: 0.6990\n",
      "  Recall: 0.6952\n",
      "  F1 Score: 0.6970\n",
      "\n",
      "Support Vector Machine:\n",
      "  Accuracy: 0.5997\n",
      "  Precision: 0.3596\n",
      "  Recall: 0.5997\n",
      "  F1 Score: 0.4496\n",
      "\n",
      "Naive Bayes:\n",
      "  Accuracy: 0.6729\n",
      "  Precision: 0.6485\n",
      "  Recall: 0.6729\n",
      "  F1 Score: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev02chandan/Documents/Intern@MatiriAI/Credit Risk Modelling/Credit_risk_modelling/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    accuracy, precision, recall, f1_score = train_and_evaluate_model(model, x_train, x_test, y_train, y_test)\n",
    "    evaluation_results[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score\n",
    "    }\n",
    "\n",
    "# Print evaluation results for each model\n",
    "for model_name, metrics in evaluation_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data with the top 12 features\n",
    "selected_features = feature_importances.head(12)['Feature']\n",
    "y = df_encoded['Approved_Flag_Encoded']\n",
    "x = df_encoded[selected_features]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(x_train, y_train)\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb.XGBClassifier(objective='multi:softmax', num_class=4, random_state=42), param_grid=xgb_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid_search.fit(x_train, y_train)\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned models\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(best_rf_model, x_test, y_test)\n",
    "xgb_accuracy, xgb_precision, xgb_recall, xgb_f1 = evaluate_model(best_xgb_model, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Best Parameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Accuracy: 0.7702365386901224\n",
      "Precision: 0.7456240438629397\n",
      "Recall: 0.7702365386901224\n",
      "F1 Score: 0.7518259672413596\n",
      "\n",
      "XGBoost - Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Accuracy: 0.7773683584928087\n",
      "Precision: 0.7527894378041347\n",
      "Recall: 0.7773683584928087\n",
      "F1 Score: 0.7577031986379033\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRandom Forest - Best Parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(f\"Precision: {rf_precision}\")\n",
    "print(f\"Recall: {rf_recall}\")\n",
    "print(f\"F1 Score: {rf_f1}\")\n",
    "\n",
    "print(f\"\\nXGBoost - Best Parameters: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {xgb_accuracy}\")\n",
    "print(f\"Precision: {xgb_precision}\")\n",
    "print(f\"Recall: {xgb_recall}\")\n",
    "print(f\"F1 Score: {xgb_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest CV Accuracy: 0.7734403524559138 (+/- 0.006725200706978069)\n",
      "XGBoost CV Accuracy: 0.7761742817127605 (+/- 0.00533194829691741)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for the best models\n",
    "rf_cv_scores = cross_val_score(best_rf_model, x, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\nRandom Forest CV Accuracy: {rf_cv_scores.mean()} (+/- {rf_cv_scores.std() * 2})\")\n",
    "\n",
    "xgb_cv_scores = cross_val_score(best_xgb_model, x, y, cv=5, scoring='accuracy')\n",
    "print(f\"XGBoost CV Accuracy: {xgb_cv_scores.mean()} (+/- {xgb_cv_scores.std() * 2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best Random Forest model\n",
    "with open('best_rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "\n",
    "# Save the best XGBoost model\n",
    "with open('best_xgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_xgb_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
